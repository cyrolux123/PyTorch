{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classification: forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input data of shape 5*6\n",
    "input_data = torch.tensor(\n",
    "    [[-0.4421, 1.5207, 2.0607, -0.3647, 0.4691, 0.0946],\n",
    "     [0.4838, 0.4001, 0.9786, 0.7858, 0.9876, 0.5987],\n",
    "     [0.1902, 0.8507, 0.8175, 0.0994, 0.3862, 0.0132],\n",
    "     [0.1973, 0.6625, 0.8123, 0.4483, 0.0345, 0.4165],\n",
    "     [0.6948, 0.3557, 0.7689, 0.2793, 0.6816, 0.9152]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # First linear layer\n",
    "    nn.Linear(4,1), # Second linear layer\n",
    "    nn.Sigmoid() # Sigmoid activation function\n",
    ")\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6753],\n",
      "        [0.6362],\n",
      "        [0.6204],\n",
      "        [0.6026],\n",
      "        [0.6195]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output) \n",
    "# Ouputs are five probabilities between 0 and 1\n",
    "# It gives one value for each sample(row) in data\n",
    "\n",
    "# Classification\n",
    "# Class = 0 for first and third values\n",
    "# Class = 1 for second, fourth and fifth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Specify model has three classes\n",
    "n_classes = 3\n",
    "\n",
    "# Create multi-class classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # First linear layer\n",
    "    nn.Linear(4,n_classes), # Second linear layer\n",
    "    nn.Softmax(dim = -1) # Softmax activation function\n",
    ")\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)\n",
    "print(output.shape) # Output shape is 5*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2601, 0.4146, 0.3253],\n",
      "        [0.1531, 0.4248, 0.4221],\n",
      "        [0.2217, 0.4337, 0.3446],\n",
      "        [0.2073, 0.4400, 0.3527],\n",
      "        [0.1676, 0.4247, 0.4077]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "\n",
    "# Each row sums to one\n",
    "# Value with highest probability is assigned predicted label in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6425],\n",
      "        [-0.3394],\n",
      "        [-0.2734],\n",
      "        [-0.2111],\n",
      "        [-0.1788]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Regression : Forwards pass\n",
    "\n",
    "# Create regression model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # First linear layer\n",
    "    nn.Linear(4,1) # Second linear layer\n",
    ")\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a binary classifier in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a small neural network with a single linear layer followed by a sigmoid function is a binary classifier. It acts just like a logistic regression.\n",
    "\n",
    "In this exercise, you'll practice building this small network and interpreting the output of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4376]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8,1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8533]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Regression model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 8),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Linear(2, 1)\n",
    "    )\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1926, 0.1312, 0.4520, 0.2242]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4), \n",
    "  nn.Softmax(dim = -1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE Manually\n",
    "import numpy as np\n",
    "one_hot_numpy = np.array([1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prevent doing manually\n",
    "\n",
    "import torch.nn.functional as f\n",
    "f.one_hot(torch.tensor(0), num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.one_hot(torch.tensor(1), num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.one_hot(torch.tensor(2), num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8131, dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Entropy Loss in PyTorch\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "scores = torch.tensor([[-0.1211, 0.1059]])\n",
    "one_hot_target = torch.tensor([[1,0]])\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "criterion(scores.double(), one_hot_target.double())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating one-hot encoded labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding is a technique that turns a single integer label into a vector of N elements, where N is the number of classes in your dataset. This vector only contains zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([1 if i == y else 0 for i in range(num_classes)])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = torch.nn.functional.one_hot(torch.tensor(y), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy loss is the most used loss for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 9.8917e-02,  1.2458e-01,  4.3436e-02,  9.9884e-03, -4.9308e-02,\n",
       "          -1.1496e-01,  9.6628e-02,  9.4046e-05, -4.2432e-02,  2.4937e-02,\n",
       "           1.5690e-02,  2.9455e-02,  2.2989e-02, -9.1310e-02, -5.2834e-02,\n",
       "          -3.2926e-02],\n",
       "         [ 9.2879e-02,  1.1698e-01,  4.0785e-02,  9.3786e-03, -4.6298e-02,\n",
       "          -1.0794e-01,  9.0729e-02,  8.8305e-05, -3.9841e-02,  2.3415e-02,\n",
       "           1.4732e-02,  2.7657e-02,  2.1586e-02, -8.5736e-02, -4.9609e-02,\n",
       "          -3.0916e-02],\n",
       "         [ 2.7301e-01,  3.4385e-01,  1.1988e-01,  2.7568e-02, -1.3609e-01,\n",
       "          -3.1729e-01,  2.6669e-01,  2.5957e-04, -1.1711e-01,  6.8827e-02,\n",
       "           4.3305e-02,  8.1296e-02,  6.3451e-02, -2.5202e-01, -1.4582e-01,\n",
       "          -9.0877e-02],\n",
       "         [ 3.2392e-03,  4.0797e-03,  1.4224e-03,  3.2708e-04, -1.6147e-03,\n",
       "          -3.7645e-03,  3.1642e-03,  3.0797e-06, -1.3895e-03,  8.1660e-04,\n",
       "           5.1379e-04,  9.6455e-04,  7.5282e-04, -2.9901e-03, -1.7301e-03,\n",
       "          -1.0782e-03],\n",
       "         [-6.2791e-02, -7.9084e-02, -2.7573e-02, -6.3405e-03,  3.1300e-02,\n",
       "           7.2975e-02, -6.1338e-02, -5.9699e-05,  2.6935e-02, -1.5830e-02,\n",
       "          -9.9598e-03, -1.8698e-02, -1.4593e-02,  5.7962e-02,  3.3538e-02,\n",
       "           2.0901e-02],\n",
       "         [ 2.2558e-01,  2.8411e-01,  9.9055e-02,  2.2778e-02, -1.1245e-01,\n",
       "          -2.6216e-01,  2.2036e-01,  2.1447e-04, -9.6764e-02,  5.6869e-02,\n",
       "           3.5781e-02,  6.7171e-02,  5.2426e-02, -2.0823e-01, -1.2049e-01,\n",
       "          -7.5087e-02],\n",
       "         [-5.5243e-02, -6.9576e-02, -2.4258e-02, -5.5782e-03,  2.7537e-02,\n",
       "           6.4202e-02, -5.3964e-02, -5.2522e-05,  2.3697e-02, -1.3927e-02,\n",
       "          -8.7625e-03, -1.6450e-02, -1.2839e-02,  5.0994e-02,  2.9507e-02,\n",
       "           1.8388e-02],\n",
       "         [-1.1182e-01, -1.4083e-01, -4.9101e-02, -1.1291e-02,  5.5739e-02,\n",
       "           1.2995e-01, -1.0923e-01, -1.0631e-04,  4.7966e-02, -2.8189e-02,\n",
       "          -1.7736e-02, -3.3297e-02, -2.5988e-02,  1.0322e-01,  5.9725e-02,\n",
       "           3.7220e-02]]),\n",
       " tensor([ 0.0763,  0.0717,  0.2107,  0.0025, -0.0485,  0.1741, -0.0426, -0.0863]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model and run a forward pass\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(16,8),\n",
    "    nn.Linear(8,4),\n",
    "    nn.Linear(4,2)\n",
    ")\n",
    "\n",
    "# Sample input tensor\n",
    "sample = torch.randn(1, 16)\n",
    "\n",
    "# Sample target tensor (class index)\n",
    "target = torch.tensor([1])\n",
    "\n",
    "prediction = model(sample)\n",
    "\n",
    "# Calculate the loss and compute the gradients\n",
    "criterion = CrossEntropyLoss()\n",
    "loss = criterion(prediction, target)\n",
    "loss.backward()\n",
    "\n",
    "# Access each layer's gradients\n",
    "model[0].weight.grad, model[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0126, -0.0069, -0.0019,  0.0038,  0.0010, -0.0057,  0.0021,  0.0072],\n",
       "         [-0.5167,  0.2835,  0.0780, -0.1550, -0.0396,  0.2355, -0.0873, -0.2977],\n",
       "         [-0.4386,  0.2407,  0.0662, -0.1316, -0.0336,  0.1999, -0.0741, -0.2528],\n",
       "         [ 0.0567, -0.0311, -0.0086,  0.0170,  0.0043, -0.0258,  0.0096,  0.0327]]),\n",
       " tensor([-0.0113,  0.4646,  0.3945, -0.0510]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.grad, model[1].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0291,  0.2597,  0.2738,  0.1583],\n",
       "         [ 0.0291, -0.2597, -0.2738, -0.1583]]),\n",
       " tensor([ 0.6752, -0.6752]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight.grad, model[2].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating model parameters manually\n",
    "\n",
    "# learning rate is typically small\n",
    "lr = 0.001\n",
    "\n",
    "# Update the weights\n",
    "weight = model[0].weight\n",
    "weight_grad = model[0].weight.grad\n",
    "weight = weight - lr * weight_grad\n",
    "\n",
    "# Update the biases\n",
    "bias = model[0].bias\n",
    "bias_grad = model[0].bias.grad\n",
    "bias = bias - lr * bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(8, 2))\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[2].bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
