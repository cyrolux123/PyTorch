{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classification: forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input data of shape 5*6\n",
    "input_data = torch.tensor(\n",
    "    [[-0.4421, 1.5207, 2.0607, -0.3647, 0.4691, 0.0946],\n",
    "     [0.4838, 0.4001, 0.9786, 0.7858, 0.9876, 0.5987],\n",
    "     [0.1902, 0.8507, 0.8175, 0.0994, 0.3862, 0.0132],\n",
    "     [0.1973, 0.6625, 0.8123, 0.4483, 0.0345, 0.4165],\n",
    "     [0.6948, 0.3557, 0.7689, 0.2793, 0.6816, 0.9152]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # First linear layer\n",
    "    nn.Linear(4,1), # Second linear layer\n",
    "    nn.Sigmoid() # Sigmoid activation function\n",
    ")\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4647],\n",
      "        [0.4493],\n",
      "        [0.4568],\n",
      "        [0.4505],\n",
      "        [0.4582]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output) \n",
    "# Ouputs are five probabilities between 0 and 1\n",
    "# It gives one value for each sample(row) in data\n",
    "\n",
    "# Classification\n",
    "# Class = 0 for first and third values\n",
    "# Class = 1 for second, fourth and fifth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Specify model has three classes\n",
    "n_classes = 3\n",
    "\n",
    "# Create multi-class classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # First linear layer\n",
    "    nn.Linear(4,n_classes), # Second linear layer\n",
    "    nn.Softmax(dim = -1) # Softmax activation function\n",
    ")\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)\n",
    "print(output.shape) # Output shape is 5*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2884, 0.4384, 0.2732],\n",
      "        [0.3075, 0.4194, 0.2731],\n",
      "        [0.3294, 0.4034, 0.2672],\n",
      "        [0.3096, 0.4249, 0.2655],\n",
      "        [0.2933, 0.4384, 0.2683]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "\n",
    "# Each row sums to one\n",
    "# Value with highest probability is assigned predicted label in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1507],\n",
      "        [0.7421],\n",
      "        [0.3649],\n",
      "        [0.3432],\n",
      "        [0.8036]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Regression : Forwards pass\n",
    "\n",
    "# Create regression model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4), # First linear layer\n",
    "    nn.Linear(4,1) # Second linear layer\n",
    ")\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a binary classifier in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a small neural network with a single linear layer followed by a sigmoid function is a binary classifier. It acts just like a logistic regression.\n",
    "\n",
    "In this exercise, you'll practice building this small network and interpreting the output of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0518]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8,1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2995]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Regression model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 8),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Linear(2, 1)\n",
    "    )\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0819, 0.0649, 0.4576, 0.3957]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4), \n",
    "  nn.Softmax(dim = -1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE Manually\n",
    "import numpy as np\n",
    "one_hot_numpy = np.array([1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prevent doing manually\n",
    "\n",
    "import torch.nn.functional as f\n",
    "f.one_hot(torch.tensor(0), num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.one_hot(torch.tensor(1), num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.one_hot(torch.tensor(2), num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8131, dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Entropy Loss in PyTorch\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "scores = torch.tensor([[-0.1211, 0.1059]])\n",
    "one_hot_target = torch.tensor([[1,0]])\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "criterion(scores.double(), one_hot_target.double())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating one-hot encoded labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding is a technique that turns a single integer label into a vector of N elements, where N is the number of classes in your dataset. This vector only contains zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([1 if i == y else 0 for i in range(num_classes)])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = torch.nn.functional.one_hot(torch.tensor(y), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy loss is the most used loss for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
